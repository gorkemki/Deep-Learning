{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gorkem/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, defaultdict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points - train: 2951, test: 1266\n",
      "Time to read data: 0.027270933000000497 seconds\n",
      "Time to preprocess 2951 data points: 0.4522040829999998 seconds\n",
      "Time for stemming 2951 data points: 1.382492946000001 seconds\n",
      "Time to preprocess 1266 data points: 0.18747677100000004 seconds\n",
      "Time for stemming 1266 data points: 0.7764718169999991 seconds\n",
      "training_data_text_sparse shape with stopwords= (2951, 5166)\n",
      "training_data_text_sparse shape without stopwords= (2951, 4981)\n",
      "['be', 'them', 'within', 'five', 'all', 'and', 'around', 'had', 'it', 'again', 'here', 'they', 'much', 'own', 'ever', 'should', 'with', 'over', 'due', 'find', 'then', 'side', 'less', 'seem', 'us', 'on', 'among', 'bottom', 'will', 'can', 'are', 'most', 'whether', 'about', 'those', 'still', 'up', 'ten', 'might', 'bill', 'against', 'each', 'even', 'how', 'cant', 'were', 'is', 'four', 'may', 'former', 'per', 'under', 'their', 'move', 'him', 'in', 'her', 'fill', 'these', 'thin', 'system', 'almost', 'amount', 'enough', 'call', 'after', 'few', 'itself', 'yet', 'full', 'such', 'been', 'mill', 'toward', 'least', 'show', 'beyond', 'off', 'neither', 'latter', 'interest', 'as', 'where', 'although', 'whose', 'see', 'also', 'keep', 're', 'who', 'have', 'detail', 'below', 'done', 'our', 'into', 'de', 'that', 'both', 'etc', 'one', 'six', 'two', 'some', 'back', 'nine', 'do', 'whole', 'the', 'what', 'she', 'not', 'upon', 'my', 'further', 'well', 'front', 'put', 'must', 'third', 'but', 'made', 'next', 'out', 'fire', 'ltd', 'along', 'take', 'inc', 'eleven', 'if', 'part', 'which', 'an', 'at', 'eight', 'from', 'name', 'across', 'now', 'nor', 'first', 'nevertheless', 'go', 'by', 'no', 'get', 'therein', 'top', 'between', 'for', 'co', 'via', 'to', 'would', 'behind', 'of', 'could', 'through', 'than', 'too', 'when', 'last', 'you', 'whom', 'until', 'while', 'am', 'without', 'other', 'more', 'mine', 'found', 'so', 'give', 'or', 'he', 'three', 'onto', 'there', 'throughout', 'we', 'same', 'your', 'down']\n",
      "Shape Before Smote= (2951,)\n",
      "Shape After Smote= (4365,)\n",
      "Time to train on 2951 data points: 1.3020913800000002 seconds\n",
      "shape test= (1266, 2) shape pred= (1266,) \n",
      "b shape= (1266, 3)\n",
      "['negative'\n",
      " 'accord to finnish petrol station chain st manag director kim wiio the compani wa forc to make purchas with rise price in the first half of and now consum price are go down almost daili due to competit '\n",
      " 'negative']\n",
      "Time to apply classifier on 1266 data points: 0.032751437999998245 seconds\n",
      "\n",
      "Test Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative     0.6810    0.7208    0.7003       154\n",
      "    neutral     0.8453    0.9120    0.8774       761\n",
      "   positive     0.8227    0.6610    0.7330       351\n",
      "\n",
      "avg / total     0.8191    0.8191    0.8158      1266\n",
      "\n",
      "LinearSVC(C=0.39, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas\n",
    "import re\n",
    "import string\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns\n",
    "\n",
    "def read_data():\n",
    "    \"\"\"\n",
    "    Read train/test data\n",
    "\n",
    "    Returns:\n",
    "    train -- Training dataframe, with 'sentence' and 'label'\n",
    "    test -- Testing dataframe, with 'sentence' and 'label'\n",
    "    \"\"\"\n",
    "    start = timer()\n",
    "    train = pandas.read_csv(\"training.tsv\", sep = \"\\t\", encoding = \"utf-8\")\n",
    "    test = pandas.read_csv(\"testing.tsv\", sep = \"\\t\", encoding = \"utf-8\")\n",
    "  \n",
    "    \n",
    "    end = timer()\n",
    "    print (\"Number of data points - train: {}, test: {}\".format(train.shape[0], test.shape[0]))\n",
    "    print (\"Time to read data: {} seconds\".format(end - start))\n",
    "    \n",
    "    sns.countplot(x='label', data=train)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess data:\n",
    "    -- strip spaces and lowercase\n",
    "    -- get rid of numbers\n",
    "    -- get rid of punctuations\n",
    "    -- get rid of single letters\n",
    "\n",
    "    Keyword arguments:\n",
    "    df -- Input two column dataframe with 'sentence' and 'label'\n",
    "\n",
    "    Returns:\n",
    "    df -- With preprocessed 'sentence' column and 'label'\n",
    "    \"\"\"\n",
    "\n",
    "    def preprocessor(sentence):\n",
    "        sentence = sentence.strip().lower()\n",
    "        sentence = re.sub(r\"\\d+\", \"\", sentence)\n",
    "        sentence = sentence.translate(sentence.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "        sentence = \" \".join([w for w in nltk.word_tokenize(sentence) if len(w) > 1])\n",
    "        \n",
    "        return sentence\n",
    "\n",
    "    start = timer()\n",
    "    df[\"sentence\"] = df[\"sentence\"].apply(preprocessor)\n",
    "\n",
    "    end = timer()\n",
    "    print (\"Time to preprocess {} data points: {} seconds\".format(df.shape[0], end - start))\n",
    "    return df\n",
    "\n",
    "\n",
    "def stemmed_text(df):\n",
    "    \n",
    "    from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "    porter = PorterStemmer()\n",
    "    def stemSentence(sentence):\n",
    "        token_words=word_tokenize(sentence)\n",
    "        stem_sentence=[]\n",
    "        for word in token_words:\n",
    "            stem_sentence.append(porter.stem(word))\n",
    "            stem_sentence.append(\" \")\n",
    "        return \"\".join(stem_sentence)\n",
    "        \n",
    "\n",
    "    start = timer()\n",
    "    df[\"sentence\"] = df[\"sentence\"].apply(stemSentence)\n",
    "\n",
    "    end = timer()\n",
    "    print (\"Time for stemming {} data points: {} seconds\".format(df.shape[0], end - start))\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def train_clf(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Train classifier\n",
    "    -- logistic regression\n",
    "    -- with TFIDF features\n",
    "\n",
    "    Keyword arguments:\n",
    "    df -- Input two column dataframe with 'sentence' and 'label'\n",
    "\n",
    "    Returns:\n",
    "    vec -- Fitted vectorizer\n",
    "    clf -- Fitted classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    start = timer()\n",
    "    vec = TfidfVectorizer(max_features = 6000)\n",
    "    training_data_text_sparse = vec.fit_transform(df[\"sentence\"])\n",
    "    \n",
    "    print(\"training_data_text_sparse shape with stopwords=\", training_data_text_sparse.shape)\n",
    "    \n",
    "    A= vec.get_feature_names()\n",
    "    \n",
    "    vec2 = TfidfVectorizer(max_features = 6000,stop_words='english')\n",
    "    training_data_text_sparse2 = vec2.fit_transform(df[\"sentence\"])\n",
    "    B= vec2.get_feature_names()\n",
    "    \n",
    "    print(\"training_data_text_sparse shape without stopwords=\", training_data_text_sparse2.shape)\n",
    "    \n",
    "    print(list(set(A) - set(B)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    print(df[\"sentence\"][1])\n",
    "    print([training_data_text_sparse[1,vec.vocabulary_['industri']]])\n",
    "    print([training_data_text_sparse[1,vec.vocabulary_['custom']]])\n",
    "    print([training_data_text_sparse[1,vec.vocabulary_['individu']]])\n",
    "    print([training_data_text_sparse[1,vec.vocabulary_['it']]])\n",
    "    print(training_data_text_sparse)\n",
    "   \n",
    "    print(\"training_data_text_sparse shape=\", training_data_text_sparse.shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Shape Before Smote=\",df[\"label\"].shape)\n",
    "    #SMOTE\n",
    "    sm = SMOTE('minority',random_state=4)\n",
    "    #sm = SMOTE('not majority',random_state=4)\n",
    "    #sm = SMOTE('auto',random_state=4)\n",
    "    sm_xtrain_tfidf, sm_train_y = sm.fit_sample(training_data_text_sparse, df[\"label\"])\n",
    "    print(\"Shape After Smote=\",sm_train_y.shape)\n",
    "    \n",
    "    sns.countplot(x=sm_train_y, data=df)\n",
    "    \n",
    "    clf = LinearSVC(C=0.39,random_state = 42)\n",
    "    clf.fit(sm_xtrain_tfidf, sm_train_y)\n",
    "    \n",
    "    end = timer()\n",
    "    print (\"Time to train on {} data points: {} seconds\".format(df.shape[0], end - start))\n",
    "\n",
    "    return vec, clf\n",
    "\n",
    "\n",
    "def evaluate_clf(vec, clf, df):\n",
    "    \"\"\"\n",
    "    Calculate classification performance on test set\n",
    "    \n",
    "    Keyword arguments:\n",
    "    vec -- Fitted vectorizer\n",
    "    clf -- Fitted classifier\n",
    "    df -- Two column test dataframe with 'sentence' and 'label'\n",
    "    \"\"\"\n",
    "    start = timer()\n",
    "    testing_data_text_sparse = vec.transform(df[\"sentence\"])\n",
    "    pred = clf.predict(testing_data_text_sparse)\n",
    "    \n",
    "    print (\"shape test= {} shape pred= {} \".format(test.shape, pred.shape))\n",
    "    import numpy as np\n",
    "    a=np.array(test)\n",
    "    pred=pred.reshape(1266,1)\n",
    "    \n",
    "    b=np.append(a, pred, axis=1)\n",
    "    print(\"b shape=\",b.shape)\n",
    "    #print(\"b=\",b)\n",
    "    #print(test.loc[13,:])\n",
    "    print(b[0])\n",
    "    #print (\"Sentence= {} Actual= {} Pred= {}\".format(df[\"sentence\"], df[\"label\"],pred))\n",
    "    \n",
    "    end = timer()\n",
    "    print (\"Time to apply classifier on {} data points: {} seconds\".format(df.shape[0], end - start))\n",
    "\n",
    "    print (\"\\nTest Report:\")\n",
    "    print (classification_report(df[\"label\"], pred, digits = 4))\n",
    "\n",
    "def load_model(clf):\n",
    "    \n",
    "    import pickle\n",
    "    pickle.dump(clf,open(\"LinSVC.pkl\",\"wb\"))\n",
    "    my_class_model=pickle.load(open(\"LinSVC.pkl\",\"rb\"))\n",
    "    print(my_class_model)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train, test = read_data()\n",
    "    train = preprocess_data(train)\n",
    "    train = stemmed_text(train)\n",
    "    test = preprocess_data(test)\n",
    "    test = stemmed_text(test)\n",
    "    vec, clf = train_clf(train)\n",
    "    evaluate_clf(vec, clf, test)\n",
    "    load_model(clf)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Baseline Model Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative     0.5789    0.5000    0.5366       154\n",
    "     neutral     0.7844    0.9277    0.8501       761\n",
    "    positive     0.7725    0.5128    0.6164       351\n",
    "\n",
    "    accuracy                         0.7607      1266\n",
    "    macro avg    0.7120    0.6468    0.6677      1266\n",
    "weighted avg     0.7561    0.7607    0.7472      1266\n",
    "\n",
    "\n",
    "    LinearSVC Model Report:\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "    negative     0.6810    0.7208    0.7003       154\n",
    "     neutral     0.8453    0.9120    0.8774       761\n",
    "    positive     0.8227    0.6610    0.7330       351\n",
    "\n",
    "    accuracy                         0.8191      1266\n",
    "   macro avg     0.7830    0.7646    0.7702      1266\n",
    "weighted avg     0.8191    0.8191    0.8158      1266\n",
    "\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
